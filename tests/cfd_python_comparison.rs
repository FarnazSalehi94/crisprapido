//! Integration tests comparing Rust CFD implementation to Python reference
//!
//! These tests read expected values generated by the Python reference implementation
//! from lindayqlin/CFD_score_calculator and verify our Rust implementation matches.

use crisprapido::cfd_score;
use serde::Deserialize;
use std::fs;

#[derive(Debug, Deserialize)]
struct TestCase {
    spacer: String,
    protospacer: String,
    pam: String,
    expected_score: Option<f64>,
    expected_error: Option<String>,
    description: String,
}

/// Load test cases from the JSON file generated by Python
fn load_test_cases() -> Vec<TestCase> {
    let json_path = "tests/python_comparison/expected_values.json";
    let json_content = fs::read_to_string(json_path)
        .expect("Failed to read test cases JSON file. Run 'python3 tests/python_comparison/generate_test_cases.py' first.");
    serde_json::from_str(&json_content).expect("Failed to parse test cases JSON")
}

/// Main test that compares all test cases against Python reference
#[test]
fn test_cfd_against_python_reference() {
    // Initialize scoring matrices
    cfd_score::init_score_matrices("mismatch_scores.txt", "pam_scores.txt")
        .expect("Failed to initialize scoring matrices");

    let test_cases = load_test_cases();
    let tolerance = 1e-6; // Allow small floating point differences

    let mut passed = 0;
    let mut failed = 0;
    let mut failed_cases: Vec<String> = Vec::new();

    for (i, tc) in test_cases.iter().enumerate() {
        let result = cfd_score::calculate_cfd(&tc.spacer, &tc.protospacer, &tc.pam);

        match (&tc.expected_score, &tc.expected_error, result) {
            // Expected a score, got a score - compare values
            (Some(expected), None, Ok(actual)) => {
                let diff = (expected - actual).abs();
                if diff < tolerance {
                    passed += 1;
                } else {
                    failed += 1;
                    failed_cases.push(format!(
                        "Case {}: {} - Expected {:.9}, got {:.9} (diff: {:.9})\n  spacer: {}\n  proto:  {}\n  pam: {}",
                        i + 1, tc.description, expected, actual, diff,
                        tc.spacer, tc.protospacer, tc.pam
                    ));
                }
            }
            // Expected an error, got an error - pass
            (None, Some(_expected_err), Err(_actual_err)) => {
                passed += 1;
            }
            // Expected a score, got an error - fail
            (Some(expected), None, Err(err)) => {
                failed += 1;
                failed_cases.push(format!(
                    "Case {}: {} - Expected score {:.9}, got error: {}\n  spacer: {}\n  proto:  {}\n  pam: {}",
                    i + 1, tc.description, expected, err,
                    tc.spacer, tc.protospacer, tc.pam
                ));
            }
            // Expected an error, got a score - fail
            (None, Some(expected_err), Ok(actual)) => {
                failed += 1;
                failed_cases.push(format!(
                    "Case {}: {} - Expected error '{}', got score {:.9}\n  spacer: {}\n  proto:  {}\n  pam: {}",
                    i + 1, tc.description, expected_err, actual,
                    tc.spacer, tc.protospacer, tc.pam
                ));
            }
            // No expected value - skip
            (None, None, _) => {
                // This shouldn't happen with well-formed test data
            }
            // Unexpected combination
            _ => {
                failed += 1;
                failed_cases.push(format!(
                    "Case {}: {} - Unexpected test case structure",
                    i + 1,
                    tc.description
                ));
            }
        }
    }

    // Print summary
    println!("\n=== CFD Python Comparison Test Results ===");
    println!("Total test cases: {}", test_cases.len());
    println!("Passed: {}", passed);
    println!("Failed: {}", failed);

    if !failed_cases.is_empty() {
        println!("\n=== Failed Cases ===");
        for fc in &failed_cases {
            println!("{}\n", fc);
        }
    }

    // Assert all tests passed
    assert!(
        failed == 0,
        "{} test cases failed out of {}. See output above for details.",
        failed,
        test_cases.len()
    );
}

/// Test perfect match cases specifically
#[test]
fn test_perfect_matches_with_various_pams() {
    cfd_score::init_score_matrices("mismatch_scores.txt", "pam_scores.txt")
        .expect("Failed to initialize scoring matrices");

    let base_seq = "GAAACAGTCGATTTTATCAC";

    // GG PAM should give 1.0
    let score = cfd_score::calculate_cfd(base_seq, base_seq, "GG").unwrap();
    assert!(
        (score - 1.0).abs() < 1e-9,
        "Perfect match with GG should be 1.0, got {}",
        score
    );

    // AG PAM should be reduced
    let score = cfd_score::calculate_cfd(base_seq, base_seq, "AG").unwrap();
    assert!(score < 1.0, "AG PAM should reduce score from 1.0");
    assert!(score > 0.0, "AG PAM should not be zero");
}

/// Test gap handling at position 1 (PAM-distal)
#[test]
fn test_gap_at_position_1() {
    cfd_score::init_score_matrices("mismatch_scores.txt", "pam_scores.txt")
        .expect("Failed to initialize scoring matrices");

    // Gap in spacer at position 1 should have no penalty
    let spacer = "-AAACAGTCGATTTTATCAC";
    let proto = "GAAACAGTCGATTTTATCAC";
    let score = cfd_score::calculate_cfd(spacer, proto, "GG").unwrap();

    // Score should be 1.0 (no penalty for position 1 gap)
    assert!(
        (score - 1.0).abs() < 1e-6,
        "Gap at position 1 should have score 1.0, got {}",
        score
    );

    // Gap in protospacer at position 1 should also have no penalty
    let spacer = "GAAACAGTCGATTTTATCAC";
    let proto = "-AAACAGTCGATTTTATCAC";
    let score = cfd_score::calculate_cfd(spacer, proto, "GG").unwrap();

    assert!(
        (score - 1.0).abs() < 1e-6,
        "Gap at position 1 in protospacer should have score 1.0, got {}",
        score
    );
}

/// Test gap handling at positions 2-20
#[test]
fn test_gaps_at_other_positions() {
    cfd_score::init_score_matrices("mismatch_scores.txt", "pam_scores.txt")
        .expect("Failed to initialize scoring matrices");

    let base_seq = "GAAACAGTCGATTTTATCAC";

    // Gap at position 2 should have a penalty
    let spacer = "G-AACAGTCGATTTTATCAC";
    let score = cfd_score::calculate_cfd(spacer, base_seq, "GG").unwrap();
    assert!(
        score < 1.0,
        "Gap at position 2 should have score < 1.0, got {}",
        score
    );

    // Some positions should give score 0
    // (based on the scoring matrix which has 0.0 for some gap positions)
    let spacer = "GAAACA-TCGATTTTATCAC"; // Gap at position 7
    let score = cfd_score::calculate_cfd(spacer, base_seq, "GG").unwrap();
    assert!(
        (score - 0.0).abs() < 1e-9,
        "Gap at position 7 should have score 0.0, got {}",
        score
    );
}

/// Test CIGAR-based CFD calculation
#[test]
fn test_cigar_based_cfd() {
    cfd_score::init_score_matrices("mismatch_scores.txt", "pam_scores.txt")
        .expect("Failed to initialize scoring matrices");

    let guide = b"ATCGATCGATCGATCGATCG";
    let target = b"ATCGATCGATCGATCGATCG";

    // Perfect match with no-op CIGAR
    let score = cfd_score::get_cfd_score(guide, target, "20=", "GG").unwrap();
    assert!(
        (score - 1.0).abs() < 1e-6,
        "Perfect match should be 1.0, got {}",
        score
    );

    // Test with mismatch CIGAR - use position 10 which definitely has a penalty
    // A->C at position 10 should have score < 1.0
    let guide_mm = b"ATCGATCGATCGATCGATCG";
    let target_mm = b"ATCGATCGACCGATCGATCG"; // T->C at position 10
    let score = cfd_score::get_cfd_score(guide_mm, target_mm, "9=1X10=", "GG").unwrap();
    // Note: Position 1 mismatches can have score 1.0 (e.g., A->T),
    // but position 10 mismatches will have reduced scores
    assert!(
        score < 1.0,
        "Mismatch at position 10 should reduce score, got {}",
        score
    );

    // Test with insertion CIGAR (gap in target)
    let guide_long = b"ATCGATCGATCGATCGATCGA"; // 21bp guide
    let target_short = b"ATCGATCGATCGATCGATCG"; // 20bp target
    let score = cfd_score::get_cfd_score(guide_long, target_short, "20=1I", "GG");
    // This should still work by truncating to 20bp
    assert!(score.is_some(), "Should handle insertion CIGAR");
}

/// Test case sensitivity
#[test]
fn test_case_sensitivity() {
    cfd_score::init_score_matrices("mismatch_scores.txt", "pam_scores.txt")
        .expect("Failed to initialize scoring matrices");

    let upper = "GAAACAGTCGATTTTATCAC";
    let lower = "gaaacagtcgattttatcac";

    // Upper/upper
    let score_upper = cfd_score::calculate_cfd(upper, upper, "GG").unwrap();

    // Lower/upper
    let score_mixed1 = cfd_score::calculate_cfd(lower, upper, "GG").unwrap();

    // Upper/lower
    let score_mixed2 = cfd_score::calculate_cfd(upper, lower, "GG").unwrap();

    // Lower/lower
    let score_lower = cfd_score::calculate_cfd(lower, lower, "gg").unwrap();

    // All should be equal (case insensitive)
    assert!(
        (score_upper - score_mixed1).abs() < 1e-9,
        "Case sensitivity issue: upper={}, mixed1={}",
        score_upper,
        score_mixed1
    );
    assert!(
        (score_upper - score_mixed2).abs() < 1e-9,
        "Case sensitivity issue: upper={}, mixed2={}",
        score_upper,
        score_mixed2
    );
    assert!(
        (score_upper - score_lower).abs() < 1e-9,
        "Case sensitivity issue: upper={}, lower={}",
        score_upper,
        score_lower
    );
}
